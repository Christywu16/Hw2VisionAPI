{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This project aims to evaluate the performance of the Google Cloud Vision API in image recognizing, more specifically, detecting objects within a set of images. I tried OpenAI API first but it's not accessible for some reason, I searched this problem but not seeing a solution beyond same probem complains, so I decideed to shift to Microsoft (I put the progress in the end of this notebook). My dataset consists a list of 10 images, each depicting distinct objects or scenes, such as animals, vehicles, and landscapes. I put the 'ground trut'of the object in the picture base on human judgement. I hypothesize that the Vision API will accurately identify and classify the majority of the objects in the images, given its advanced machine learning models. But not necessarily perfect align with my 'ground truth' column since there could be various names, bias or confusion of the main object. This analysis will provide insights into the API's capabilities and potential areas of improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hvae 2 ground truth dataset, one is I labeled only 1 word for each image, another is I labeled a few different word for each image. Below, I will compare and analyze the accuracy of each of them against the Vision API result. The ranging from singular to multiple descriptors is to encapsulate the varied and complex nature of visual content. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For setting up Google Vision API vikrtual environment, I referenced:\n",
    "\n",
    "https://www.youtube.com/watch?v=kZ3OL3AN_IA&list=PL3JVwFmb_BnRY8qaG5S1MhtlxTOgE-_k0&index=1\n",
    "\n",
    "OpenAI Vision API Error:\n",
    "\n",
    "https://github.com/OthersideAI/self-operating-computer/issues/26 \n",
    "\n",
    "\n",
    "Some image resources on Google, some others are from my own photos. The dataset comprises diverse subjects, including animals, landscapes, and urban scenes, chosen to test the API's ability to accurately recognize and label a wide array of elements within images. The motivation behind using this dataset was to assess how well the API can handle the multifaceted aspects of real-world images, with a specific hypothesis that the API might underperform on images with ambiguous or overlapping categories (e.g., an image labeled both \"park\" and \"grass\"). By employing a dataset with both singular and multiple labels, we aimed to measure the API's precision in not just identifying primary objects but also in capturing the broader context and secondary elements present in the images, thus providing a comprehensive evaluation of its capabilities and limitations.\n",
    "\n",
    "Image resources:\n",
    "\n",
    "4: https://www.vanorohotel.com/wp-content/uploads/2021/07/drz-vanoro_6737.jpg\n",
    "\n",
    "5: https://thumbs.dreamstime.com/b/couple-dating-hugging-love-park-urban-sunny-day-51723735.jpg\n",
    "\n",
    "6: https://thumbs.dreamstime.com/b/couple-dating-hugging-love-park-urban-sunny-day-51723735.jpg\n",
    "\n",
    "7: https://climate.nasa.gov/system/internal_resources/details/original/309_ImageWall5_768px-60.jpg \n",
    "\n",
    "8: https://images.pexels.com/photos/5847385/pexels-photo-5847385.jpeg?cs=srgb&dl=pexels-charles-parker-5847385.jpg&fm=jpg \n",
    "\n",
    "9: https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/R160_E_enters_42nd_Street.jpg/300px-R160_E_enters_42nd_Street.jpg\n",
    "\n",
    "10: https://upload.wikimedia.org/wikipedia/commons/3/35/Neckertal_20150527-6384.jpg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # install package \n",
    "# pip install google-cloud-vision pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import vision\n",
    "from google_vision_ai import VisionAI, prepare_image_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'client_file_ai_vision_demo.json'\n",
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>lighthouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img4.jpg</td>\n",
       "      <td>bedroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img5.jpg</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img6.jpg</td>\n",
       "      <td>couple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>img7.jpg</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>img8.jpg</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>img9.jpg</td>\n",
       "      <td>subway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>img10.jpg</td>\n",
       "      <td>landscape</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename       label\n",
       "0   img1.jpg         cat\n",
       "1   img2.jpg   sunflower\n",
       "2   img3.jpg  lighthouse\n",
       "3   img4.jpg     bedroom\n",
       "4   img5.jpg         car\n",
       "5   img6.jpg      couple\n",
       "6   img7.jpg       earth\n",
       "7   img8.jpg      street\n",
       "8   img9.jpg      subway\n",
       "9  img10.jpg   landscape"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data = pd.read_csv('dataset.csv')\n",
    "image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_responses = []\n",
    "\n",
    "# Iterate over each row in the DataFrame to call the API and store the response\n",
    "for index, row in image_data.iterrows():\n",
    "    image_path = f'./image/{row[\"filename\"]}'\n",
    "    image = prepare_image_local(image_path)\n",
    "    va = VisionAI(client, image)\n",
    "    label_detections = va.label_detection()\n",
    "    api_responses.append((row['filename'], label_detections))\n",
    "\n",
    "api_responses_df = pd.DataFrame(api_responses, columns=['Image', 'API_Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>API_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>[(Cat, 0.95), (Felidae, 0.86), (Small to mediu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>[(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>[(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img4.jpg</td>\n",
       "      <td>[(Furniture, 0.96), (Building, 0.93), (Picture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img5.jpg</td>\n",
       "      <td>[(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img6.jpg</td>\n",
       "      <td>[(Smile, 0.98), (Flash photography, 0.88), (Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>img7.jpg</td>\n",
       "      <td>[(Atmosphere, 0.95), (World, 0.92), (Astronomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>img8.jpg</td>\n",
       "      <td>[(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>img9.jpg</td>\n",
       "      <td>[(Train, 0.98), (Transport hub, 0.88), (Mode o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>img10.jpg</td>\n",
       "      <td>[(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Image                                         API_Labels\n",
       "0   img1.jpg  [(Cat, 0.95), (Felidae, 0.86), (Small to mediu...\n",
       "1   img2.jpg  [(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...\n",
       "2   img3.jpg  [(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...\n",
       "3   img4.jpg  [(Furniture, 0.96), (Building, 0.93), (Picture...\n",
       "4   img5.jpg  [(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...\n",
       "5   img6.jpg  [(Smile, 0.98), (Flash photography, 0.88), (Pe...\n",
       "6   img7.jpg  [(Atmosphere, 0.95), (World, 0.92), (Astronomi...\n",
       "7   img8.jpg  [(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...\n",
       "8   img9.jpg  [(Train, 0.98), (Transport hub, 0.88), (Mode o...\n",
       "9  img10.jpg  [(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_responses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_responses_df['API_Label'] = api_responses_df['API_Labels'].apply(lambda x: x if x else 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>API_Labels</th>\n",
       "      <th>API_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>[(Cat, 0.95), (Felidae, 0.86), (Small to mediu...</td>\n",
       "      <td>[(Cat, 0.95), (Felidae, 0.86), (Small to mediu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>[(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...</td>\n",
       "      <td>[(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>[(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...</td>\n",
       "      <td>[(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img4.jpg</td>\n",
       "      <td>[(Furniture, 0.96), (Building, 0.93), (Picture...</td>\n",
       "      <td>[(Furniture, 0.96), (Building, 0.93), (Picture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img5.jpg</td>\n",
       "      <td>[(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...</td>\n",
       "      <td>[(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img6.jpg</td>\n",
       "      <td>[(Smile, 0.98), (Flash photography, 0.88), (Pe...</td>\n",
       "      <td>[(Smile, 0.98), (Flash photography, 0.88), (Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>img7.jpg</td>\n",
       "      <td>[(Atmosphere, 0.95), (World, 0.92), (Astronomi...</td>\n",
       "      <td>[(Atmosphere, 0.95), (World, 0.92), (Astronomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>img8.jpg</td>\n",
       "      <td>[(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...</td>\n",
       "      <td>[(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>img9.jpg</td>\n",
       "      <td>[(Train, 0.98), (Transport hub, 0.88), (Mode o...</td>\n",
       "      <td>[(Train, 0.98), (Transport hub, 0.88), (Mode o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>img10.jpg</td>\n",
       "      <td>[(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96...</td>\n",
       "      <td>[(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Image                                         API_Labels  \\\n",
       "0   img1.jpg  [(Cat, 0.95), (Felidae, 0.86), (Small to mediu...   \n",
       "1   img2.jpg  [(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...   \n",
       "2   img3.jpg  [(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...   \n",
       "3   img4.jpg  [(Furniture, 0.96), (Building, 0.93), (Picture...   \n",
       "4   img5.jpg  [(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...   \n",
       "5   img6.jpg  [(Smile, 0.98), (Flash photography, 0.88), (Pe...   \n",
       "6   img7.jpg  [(Atmosphere, 0.95), (World, 0.92), (Astronomi...   \n",
       "7   img8.jpg  [(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...   \n",
       "8   img9.jpg  [(Train, 0.98), (Transport hub, 0.88), (Mode o...   \n",
       "9  img10.jpg  [(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96...   \n",
       "\n",
       "                                           API_Label  \n",
       "0  [(Cat, 0.95), (Felidae, 0.86), (Small to mediu...  \n",
       "1  [(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...  \n",
       "2  [(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...  \n",
       "3  [(Furniture, 0.96), (Building, 0.93), (Picture...  \n",
       "4  [(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...  \n",
       "5  [(Smile, 0.98), (Flash photography, 0.88), (Pe...  \n",
       "6  [(Atmosphere, 0.95), (World, 0.92), (Astronomi...  \n",
       "7  [(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...  \n",
       "8  [(Train, 0.98), (Transport hub, 0.88), (Mode o...  \n",
       "9  [(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_responses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(image_data, api_responses_df, left_on='filename', right_on='Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_comparison(row):\n",
    "    ground_truth_labels = [label.strip().lower() for label in row['label'].split(',')]\n",
    "    api_labels = [label.lower() for label, _ in row['API_Label']]\n",
    "    match = any(gt_label in api_labels for gt_label in ground_truth_labels)\n",
    "    \n",
    "    return 'Match' if match else 'Mismatch'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing to single ground truth labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30\n",
      "    filename       label                                          API_Label  \\\n",
      "0   img1.jpg         cat  [(Cat, 0.95), (Felidae, 0.86), (Small to mediu...   \n",
      "1   img2.jpg   sunflower  [(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...   \n",
      "2   img3.jpg  lighthouse  [(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...   \n",
      "3   img4.jpg     bedroom  [(Furniture, 0.96), (Building, 0.93), (Picture...   \n",
      "4   img5.jpg         car  [(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...   \n",
      "5   img6.jpg      couple  [(Smile, 0.98), (Flash photography, 0.88), (Pe...   \n",
      "6   img7.jpg       earth  [(Atmosphere, 0.95), (World, 0.92), (Astronomi...   \n",
      "7   img8.jpg      street  [(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...   \n",
      "8   img9.jpg      subway  [(Train, 0.98), (Transport hub, 0.88), (Mode o...   \n",
      "9  img10.jpg   landscape  [(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96...   \n",
      "\n",
      "  Comparison  \n",
      "0      Match  \n",
      "1   Mismatch  \n",
      "2      Match  \n",
      "3   Mismatch  \n",
      "4      Match  \n",
      "5   Mismatch  \n",
      "6   Mismatch  \n",
      "7   Mismatch  \n",
      "8   Mismatch  \n",
      "9   Mismatch  \n"
     ]
    }
   ],
   "source": [
    "merged_df['Comparison'] = merged_df.apply(label_comparison, axis=1)\n",
    "accuracy = len(merged_df[merged_df['Comparison'] == 'Match']) / len(merged_df)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(merged_df[['filename', 'label', 'API_Label', 'Comparison']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single descriptor match accuracy is 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now Comparing to multiple ground truth labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>cat,floor,cable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>sunflower,window,bridge,building,leaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>lighthouse,house,eky,ground,hill,people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img4.jpg</td>\n",
       "      <td>room,bed,bedroom,couch,TV,desk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img5.jpg</td>\n",
       "      <td>car,vehicle,sportscar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img6.jpg</td>\n",
       "      <td>couple,smile,man,woman,coat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>img7.jpg</td>\n",
       "      <td>earth,planet,globe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>img8.jpg</td>\n",
       "      <td>street,building,crossing,traffic light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>img9.jpg</td>\n",
       "      <td>subway,train,station,people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>img10.jpg</td>\n",
       "      <td>landscape,tree,house,mountain,grassland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename                                    label\n",
       "0   img1.jpg                          cat,floor,cable\n",
       "1   img2.jpg    sunflower,window,bridge,building,leaf\n",
       "2   img3.jpg  lighthouse,house,eky,ground,hill,people\n",
       "3   img4.jpg           room,bed,bedroom,couch,TV,desk\n",
       "4   img5.jpg                    car,vehicle,sportscar\n",
       "5   img6.jpg              couple,smile,man,woman,coat\n",
       "6   img7.jpg                       earth,planet,globe\n",
       "7   img8.jpg   street,building,crossing,traffic light\n",
       "8   img9.jpg              subway,train,station,people\n",
       "9  img10.jpg  landscape,tree,house,mountain,grassland"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df = pd.read_csv('dataset1.csv')\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>[cat, floor, cable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>[sunflower, window, bridge, building, leaf]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>[lighthouse, house, eky, ground, hill, people]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img4.jpg</td>\n",
       "      <td>[room, bed, bedroom, couch, tv, desk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img5.jpg</td>\n",
       "      <td>[car, vehicle, sportscar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img6.jpg</td>\n",
       "      <td>[couple, smile, man, woman, coat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>img7.jpg</td>\n",
       "      <td>[earth, planet, globe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>img8.jpg</td>\n",
       "      <td>[street, building, crossing, traffic light]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>img9.jpg</td>\n",
       "      <td>[subway, train, station, people]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>img10.jpg</td>\n",
       "      <td>[landscape, tree, house, mountain, grassland]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename                                           label\n",
       "0   img1.jpg                             [cat, floor, cable]\n",
       "1   img2.jpg     [sunflower, window, bridge, building, leaf]\n",
       "2   img3.jpg  [lighthouse, house, eky, ground, hill, people]\n",
       "3   img4.jpg           [room, bed, bedroom, couch, tv, desk]\n",
       "4   img5.jpg                       [car, vehicle, sportscar]\n",
       "5   img6.jpg               [couple, smile, man, woman, coat]\n",
       "6   img7.jpg                          [earth, planet, globe]\n",
       "7   img8.jpg     [street, building, crossing, traffic light]\n",
       "8   img9.jpg                [subway, train, station, people]\n",
       "9  img10.jpg   [landscape, tree, house, mountain, grassland]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df['label'] = image_df['label'].apply(lambda x: [label.strip().lower() for label in x.split(',')] if isinstance(x, str) else x)\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df1 = pd.merge(image_df, api_responses_df, left_on='filename', right_on='Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_comparison(row):\n",
    "    ground_truth_labels = row['label']  # Already a list from previous preprocessing\n",
    "    api_labels = [label.lower() for label, _ in row['API_Label']]\n",
    "    \n",
    "    match = any(gt_label.lower() in api_labels for gt_label in ground_truth_labels)\n",
    "\n",
    "    return 'Match' if match else 'Mismatch'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df1['Comparison'] = merged_df1.apply(label_comparison, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "    filename                                           label  \\\n",
      "0   img1.jpg                             [cat, floor, cable]   \n",
      "1   img2.jpg     [sunflower, window, bridge, building, leaf]   \n",
      "2   img3.jpg  [lighthouse, house, eky, ground, hill, people]   \n",
      "3   img4.jpg           [room, bed, bedroom, couch, tv, desk]   \n",
      "4   img5.jpg                       [car, vehicle, sportscar]   \n",
      "5   img6.jpg               [couple, smile, man, woman, coat]   \n",
      "6   img7.jpg                          [earth, planet, globe]   \n",
      "7   img8.jpg     [street, building, crossing, traffic light]   \n",
      "8   img9.jpg                [subway, train, station, people]   \n",
      "9  img10.jpg   [landscape, tree, house, mountain, grassland]   \n",
      "\n",
      "                                           API_Label Comparison  \n",
      "0  [(Cat, 0.95), (Felidae, 0.86), (Small to mediu...      Match  \n",
      "1  [(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...      Match  \n",
      "2  [(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...      Match  \n",
      "3  [(Furniture, 0.96), (Building, 0.93), (Picture...   Mismatch  \n",
      "4  [(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...      Match  \n",
      "5  [(Smile, 0.98), (Flash photography, 0.88), (Pe...      Match  \n",
      "6  [(Atmosphere, 0.95), (World, 0.92), (Astronomi...      Match  \n",
      "7  [(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...      Match  \n",
      "8  [(Train, 0.98), (Transport hub, 0.88), (Mode o...      Match  \n",
      "9  [(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96...      Match  \n"
     ]
    }
   ],
   "source": [
    "merged_df1['Comparison'] = merged_df1.apply(label_comparison, axis=1)\n",
    "\n",
    "# Calculate accuracy based on matches\n",
    "accuracy = len(merged_df1[merged_df1['Comparison'] == 'Match']) / len(merged_df1)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(merged_df1[['filename', 'label', 'API_Label', 'Comparison']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>Image</th>\n",
       "      <th>API_Labels</th>\n",
       "      <th>API_Label</th>\n",
       "      <th>Comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>[cat, floor, cable]</td>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>[(Cat, 0.95), (Felidae, 0.86), (Small to mediu...</td>\n",
       "      <td>[(Cat, 0.95), (Felidae, 0.86), (Small to mediu...</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>[sunflower, window, bridge, building, leaf]</td>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>[(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...</td>\n",
       "      <td>[(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>[lighthouse, house, eky, ground, hill, people]</td>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>[(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...</td>\n",
       "      <td>[(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img4.jpg</td>\n",
       "      <td>[room, bed, bedroom, couch, tv, desk]</td>\n",
       "      <td>img4.jpg</td>\n",
       "      <td>[(Furniture, 0.96), (Building, 0.93), (Picture...</td>\n",
       "      <td>[(Furniture, 0.96), (Building, 0.93), (Picture...</td>\n",
       "      <td>Mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img5.jpg</td>\n",
       "      <td>[car, vehicle, sportscar]</td>\n",
       "      <td>img5.jpg</td>\n",
       "      <td>[(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...</td>\n",
       "      <td>[(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img6.jpg</td>\n",
       "      <td>[couple, smile, man, woman, coat]</td>\n",
       "      <td>img6.jpg</td>\n",
       "      <td>[(Smile, 0.98), (Flash photography, 0.88), (Pe...</td>\n",
       "      <td>[(Smile, 0.98), (Flash photography, 0.88), (Pe...</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>img7.jpg</td>\n",
       "      <td>[earth, planet, globe]</td>\n",
       "      <td>img7.jpg</td>\n",
       "      <td>[(Atmosphere, 0.95), (World, 0.92), (Astronomi...</td>\n",
       "      <td>[(Atmosphere, 0.95), (World, 0.92), (Astronomi...</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>img8.jpg</td>\n",
       "      <td>[street, building, crossing, traffic light]</td>\n",
       "      <td>img8.jpg</td>\n",
       "      <td>[(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...</td>\n",
       "      <td>[(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>img9.jpg</td>\n",
       "      <td>[subway, train, station, people]</td>\n",
       "      <td>img9.jpg</td>\n",
       "      <td>[(Train, 0.98), (Transport hub, 0.88), (Mode o...</td>\n",
       "      <td>[(Train, 0.98), (Transport hub, 0.88), (Mode o...</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>img10.jpg</td>\n",
       "      <td>[landscape, tree, house, mountain, grassland]</td>\n",
       "      <td>img10.jpg</td>\n",
       "      <td>[(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96...</td>\n",
       "      <td>[(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96...</td>\n",
       "      <td>Match</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename                                           label      Image  \\\n",
       "0   img1.jpg                             [cat, floor, cable]   img1.jpg   \n",
       "1   img2.jpg     [sunflower, window, bridge, building, leaf]   img2.jpg   \n",
       "2   img3.jpg  [lighthouse, house, eky, ground, hill, people]   img3.jpg   \n",
       "3   img4.jpg           [room, bed, bedroom, couch, tv, desk]   img4.jpg   \n",
       "4   img5.jpg                       [car, vehicle, sportscar]   img5.jpg   \n",
       "5   img6.jpg               [couple, smile, man, woman, coat]   img6.jpg   \n",
       "6   img7.jpg                          [earth, planet, globe]   img7.jpg   \n",
       "7   img8.jpg     [street, building, crossing, traffic light]   img8.jpg   \n",
       "8   img9.jpg                [subway, train, station, people]   img9.jpg   \n",
       "9  img10.jpg   [landscape, tree, house, mountain, grassland]  img10.jpg   \n",
       "\n",
       "                                          API_Labels  \\\n",
       "0  [(Cat, 0.95), (Felidae, 0.86), (Small to mediu...   \n",
       "1  [(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...   \n",
       "2  [(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...   \n",
       "3  [(Furniture, 0.96), (Building, 0.93), (Picture...   \n",
       "4  [(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...   \n",
       "5  [(Smile, 0.98), (Flash photography, 0.88), (Pe...   \n",
       "6  [(Atmosphere, 0.95), (World, 0.92), (Astronomi...   \n",
       "7  [(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...   \n",
       "8  [(Train, 0.98), (Transport hub, 0.88), (Mode o...   \n",
       "9  [(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96...   \n",
       "\n",
       "                                           API_Label Comparison  \n",
       "0  [(Cat, 0.95), (Felidae, 0.86), (Small to mediu...      Match  \n",
       "1  [(Flower, 0.98), (Plant, 0.95), (Sky, 0.91), (...      Match  \n",
       "2  [(Sky, 0.97), (Lighthouse, 0.96), (Building, 0...      Match  \n",
       "3  [(Furniture, 0.96), (Building, 0.93), (Picture...   Mismatch  \n",
       "4  [(Wheel, 0.98), (Tire, 0.97), (Vehicle, 0.96),...      Match  \n",
       "5  [(Smile, 0.98), (Flash photography, 0.88), (Pe...      Match  \n",
       "6  [(Atmosphere, 0.95), (World, 0.92), (Astronomi...      Match  \n",
       "7  [(Building, 0.96), (Sky, 0.96), (Skyscraper, 0...      Match  \n",
       "8  [(Train, 0.98), (Transport hub, 0.88), (Mode o...      Match  \n",
       "9  [(Cloud, 0.97), (Plant, 0.96), (Mountain, 0.96...      Match  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiple descriptor match accuracy is 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a single label, the accuracy was 30%, highlighting the challenges in matching the API's diverse predictions to a singular descriptor. However, when multiple labels were allowed, reflecting a broader understanding of each image's content, accuracy significantly increased to 90%. This improvement underscores the API's strength in recognizing a wide range of elements within an image, suggesting that it performs best when the complexity of visual content is fully acknowledged through multiple acceptable labels. This experiment's findings highlight the importance of context and the breadth of labels in evaluating image recognition technologies. The substantial difference in accuracy between the single-label and multi-label approaches emphasizes the need for flexible definitions of \"correct\" outcomes in AI applications. By allowing a range of correct labels, the utility and accuracy of image recognition APIs like Google Vision can be significantly enhanced, especially in applications requiring a nuanced understanding of visual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evelauate by Other Metrics\n",
    "\n",
    "Refcerence: https://www.linkedin.com/advice/3/what-best-practices-evaluating-performance-deep#:~:text=The%20first%20step%20in%20evaluating,%2Dscore%2C%20and%20confusion%20matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_matches(row):\n",
    "    predicted_labels = set(label[0].lower() for label in row['API_Labels'])\n",
    "    ground_truth_labels = set(label.lower() for label in row['label'])\n",
    "    matches = ground_truth_labels.intersection(predicted_labels)\n",
    "    return list(matches)\n",
    "\n",
    "# Apply the function\n",
    "merged_df1['Matches'] = merged_df1.apply(identify_matches, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00\n",
      "Recall: 0.27\n",
      "F1 Score: 0.43\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the matches\n",
    "y_true_matches = mlb_matches.fit_transform(merged_df1['label'])  # Ground truth\n",
    "y_pred_matches = mlb_matches.transform(merged_df1['Matches'])    # Predicted matches\n",
    "\n",
    "# Calculate metrics based on the binary format of matches\n",
    "precision = precision_score(y_true_matches, y_pred_matches, average='micro')\n",
    "recall = recall_score(y_true_matches, y_pred_matches, average='micro')\n",
    "f1 = f1_score(y_true_matches, y_pred_matches, average='micro')\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Precision (1.00): This suggests that the model likely predicts a label correct which indicates there are very few false positives. This aligns with my hypothesis in the begining that in most cases, model can correctly predict label.\n",
    "\n",
    "Lower Recall (0.27): This indicates that the model is missing a significant number of true labels. There are many false negatives, where the model fails to identify true labels. This could be in some images it has a lot of different ground truth labels, and the Vision AI result is not matching a majority of all groud truth labels. While more descriptor in the ground truth labels, it gives more opportunity for AI model to have one match which increases the simplified accuracy (as we see above), it also increases the false negative rates. This indicates the limiatation of AI models detecting and interpreting objects in the image and varies from human insights besides the most significant object in the image.\n",
    "\n",
    "F1 Score (0.43): The F1 score balances precision and recall in a single metric, and a score of 0.43 suggests that while precision is high, the overall effectiveness of the model (considering both precision and recall) is moderate. The low recall significantly impacts the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The result above demonstrated the strengths of the API in identifying diverse elements within images, also reveal its limitations in fully matching the human ability to discern and label multiple aspects of visual content. The substantial difference in accuracy between single-label and multi-label approaches emphasizes the importance of flexible, context-aware definitions of \"correct\" outcomes in AI applications. It suggests that for applications requiring a nuanced understanding of visual data, such as content categorization, surveillance, or aid in accessibility, leveraging a multi-label approach can significantly enhance the utility and accuracy of image recognition APIs.\n",
    "\n",
    "In conclusion, this experiment has not only validated the hypothesis that the API can correctly predict labels in many cases but also illuminated the challenges it faces in comprehensively identifying all relevant labels. The performance of Google Vision API, as evidenced by the aggregated statistics and the calculated metrics, affirms the critical role of context and label breadth in evaluating and enhancing image recognition technologies. This analysis advocates for a nuanced application of AI in image recognition, where the richness of visual content is fully embraced, thereby aligning technological capabilities more closely with human perception and understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure Process for Calling OpenAI Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      3\u001b[0m api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msk-bLMAmkgXfM4ZIdaBY7lNT3BlbkFJpNa3sgoXwhE6ufcDghWG\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = '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'\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-0314\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": 'https://cdn.britannica.com/79/232779-050-6B0411D7/German-Shepherd-dog-Alsatian.jpg',\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_vision_ai_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
